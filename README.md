# extraction-multisource
![alt text](image.png)

# RÃ©sumÃ© de ma mission principale

CrÃ©er un **pipeline unifiÃ©** pour lâ€™extraction, la transformation et lâ€™organisation des donnÃ©es provenant de plusieurs sources :

- **Base OLTP** (Adventure Works SQL),
- **Fichiers Parquet et CSV compressÃ©s** sur un Data Lake,
- **DonnÃ©es de reviews textuelles** issues de fichiers.

Ces donnÃ©es serviront ensuite aux Ã©quipes de **Data Scientists** pour construire et affiner un modÃ¨le capable dâ€™analyser Ã  la fois des donnÃ©es **textuelles** et **visuelles**.

---

## Objectifs clÃ©s de ta mission

### 1. Centraliser les donnÃ©es multi-sources

**Sources principales :**

- **Base de donnÃ©es SQL** : Extraire les donnÃ©es sur les clients, produits et ventes.
- **Data Lake (Parquet)** : Collecter et transformer les avis enrichis (texte + images).
- **Data Lake (CSV compressÃ©s)** : Extraire et organiser les donnÃ©es tabulaires.
- **Data Lake (NLP Data)** : Traiter les fichiers de reviews textuelles non structurÃ©es.

---

### 2. Automatiser les extractions

CrÃ©er des **scripts robustes** pour automatiser l'extraction des donnÃ©es depuis chaque source, tout en respectant les contraintes techniques et sÃ©curitaires :

- **Base SQL** : Programmation dâ€™extractions pendant les heures creuses (20h-8h).
- **Data Lake** : Utilisation de tokens SAS pour un accÃ¨s sÃ©curisÃ©.
- **Transformation** : Convertir les donnÃ©es brutes en fichiers CSV ou images utilisables.

---

### 3. Structurer les donnÃ©es

**Format de sortie attendu :**

- **CSV** pour les donnÃ©es tabulaires (clients, produits, ventes).
- **Images (.png)** pour les fichiers visuels extraits des fichiers Parquet.
- Un **fichier CSV** qui associe les mÃ©tadonnÃ©es des avis aux noms des images.

---

### 4. Journaliser et documenter

Concevoir un pipeline organisÃ© avec des Ã©tapes distinctes et bien documentÃ©es :

- **Extraction** : Mise en place des connexions sÃ©curisÃ©es et rÃ©cupÃ©ration des donnÃ©es.
- **Transformation** : Nettoyage et formatage des donnÃ©es.
- **Journalisation** : Logs dÃ©taillÃ©s pour suivre chaque Ã©tape du processus.
- **Versionnement** : Scripts accessibles et documentÃ©s dans un dÃ©pÃ´t Git.

---

### 5. Optimisation et sÃ©curitÃ©

**SÃ©curiser les accÃ¨s aux donnÃ©es :**

- GÃ©nÃ©ration et gestion des **tokens SAS** pour le Data Lake.
- Utilisation de bibliothÃ¨ques sÃ©curisÃ©es pour les connexions SQL.

**Optimiser les performances :**

- Limiter lâ€™impact sur les bases de production (extraction planifiÃ©e pendant les heures creuses).
- Manipuler les fichiers Parquet et CSV compressÃ©s sans Ã©tape de dÃ©compression inutile.

ğŸ“ extraction_multisource
  â”œâ”€â”€ install.sh                # Script d'installation automatique des dÃ©pendances
  â”œâ”€â”€ main.py                   # Script principal orchestrant toutes les Ã©tapes du pipeline
  â”œâ”€â”€ requirements.txt          # Liste des dÃ©pendances Python
  â”œâ”€â”€ README.md                 # Documentation du projet
  â”œâ”€â”€ .gitignore                # Fichiers et dossiers Ã  exclure du contrÃ´le de version Git
  â”œâ”€â”€ ğŸ“ src                    # Contient les scripts modulaires
  â”‚     â”œâ”€â”€ ğŸ“ extraction       # Scripts pour l'extraction des donnÃ©es
  â”‚     â”‚     â”œâ”€â”€ extract_sql.py      # Script pour extraire les donnÃ©es depuis la base SQL
  â”‚     â”‚     â”œâ”€â”€ extract_parquet.py  # Script pour extraire les fichiers Parquet
  â”‚     â”‚     â”œâ”€â”€ extract_csv.py      # Script pour extraire les fichiers CSV
  â”‚     â”œâ”€â”€ ğŸ“ transformation    # Scripts pour transformer et organiser les donnÃ©es
  â”‚     â”‚     â”œâ”€â”€ transform_to_csv.py # Transformation des donnÃ©es tabulaires en CSV
  â”‚     â”‚     â”œâ”€â”€ image_processing.py # Traitement et extraction des images encodÃ©es
  â”‚     â”œâ”€â”€ ğŸ“ utils            # Contient les outils utilitaires
  â”‚           â”œâ”€â”€ sas_generator.py    # GÃ©nÃ©ration des SAS tokens pour l'accÃ¨s au Data Lake
  â”‚           â”œâ”€â”€ logger.py           # Gestion des logs
  â”‚           â”œâ”€â”€ error_handler.py    # Gestion des erreurs et exceptions
  â”œâ”€â”€ ğŸ“ data                   # Dossier pour organiser les donnÃ©es
  â”‚     â”œâ”€â”€ ğŸ“ raw              # DonnÃ©es brutes extraites
  â”‚     â”‚     â”œâ”€â”€ sql           # DonnÃ©es issues de la base SQL
  â”‚     â”‚     â”œâ”€â”€ parquet       # DonnÃ©es extraites des fichiers Parquet
  â”‚     â”‚     â”œâ”€â”€ csv           # DonnÃ©es extraites des fichiers CSV
  â”‚     â”œâ”€â”€ ğŸ“ processed        # DonnÃ©es transformÃ©es
  â”‚           â”œâ”€â”€ csv_final     # DonnÃ©es finales en CSV
  â”‚           â”œâ”€â”€ images        # Images extraites et sauvegardÃ©es
  â”œâ”€â”€ ğŸ“ tests                  # Scripts de tests unitaires pour valider le code
        â”œâ”€â”€ test_extract_sql.py      # Tests pour le script SQL
        â”œâ”€â”€ test_extract_parquet.py  # Tests pour le script Parquet
        â”œâ”€â”€ test_transform.py        # Tests pour les transformations
